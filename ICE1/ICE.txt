In Class Exercise 1 
1.) grep for only the lines that have 2019-03-12 for their "dropoff" date (NOT pickup).
Redirect the last 20 entries (output) into a file named "results.txt" using redirection (using >)
Answer how many entries match the condition in total (using wc) by appending the count at the end of "results.txt" (using >>)

 1018  head 2019-03.csv
 1019  sort -t, -k3,3 2019-03.csv | grep "2019-03-12" | wc -l
(this sort doesnt help narrow down to the tird column b/c grep will still "see" the second pick up column.) 
(sort -t, deliminate by "," -k3,3 and sort the third column "Drop off". | grep pattern match "2019-03-12" | wc -l lines to see how many entries there are 
OUTPUT: 
268758 (and this is wrong. when i print the last 20, tail-20 it gives me dates from 2019-03-13 in the and get 2019-03-12 from the pick up)

2.0,"2019-03-12 23:00:24.000000","2019-03-13 22:37:54.000000",1.0,2.46,1.0,N,142.0,166.0,1.0,9.0,0.5,0.5,2.56,0.0,0.3,15.36,2.5
2.0,"2019-03-12 22:41:23.000000","2019-03-13 22:38:23.000000",1.0,2.28,1.0,N,236.0,170.0,2.0,11.0,0.5,0.5,0.0,0.0,0.3,14.8,2.5
2.0,"2019-03-12 22:39:42.000000","2019-03-13 22:38:38.000000",2.0,0.51,1.0,N,114.0,211.0,2.0,4.0,0.5,0.5,0.0,0.0,0.3,7.8,2.5
2.0,"2019-03-12 22:49:15.000000","2019-03-13 22:38:43.000000",1.0,16.63,1.0,N,186.0,183.0,1.0,55.0,0.5,0.5,11.76,0.0,0.3,70.56,2.5
2.0,"2019-03-12 23:29:04.000000","2019-03-13 22:38:45.000000",1.0,1.5,1.0,N,230.0,68.0,1.0,7.5,0.5,0.5,2.5,0.0,0.3,13.8,2.5
2.0,"2019-03-12 22:46:12.000000","2019-03-13 22:42:44.000000",5.0,2.44,1.0,N,61.0,35.0,1.0,10.0,0.5,0.5,0.0,0.0,0.3,11.3,0.0
2.0,"2019-03-12 23:46:28.000000","2019-03-13 22:43:05.000000",1.0,17.7,2.0,N,132.0,164.0,1.0,52.0,0.0,0.5,12.21,5.76,0.3,73.27,2.5
2.0,"2019-03-12 23:08:16.000000","2019-03-13 22:43:34.000000",1.0,3.07,1.0,N,230.0,224.0,1.0,11.5,0.5,0.5,3.06,0.0,0.3,18.36,2.5
2.0,"2019-03-12 22:45:00.000000","2019-03-13 22:44:04.000000",1.0,1.93,1.0,N,48.0,238.0,1.0,8.5,0.5,0.5,2.46,0.0,0.3,14.76,2.5
2.0,"2019-03-12 23:30:04.000000","2019-03-13 22:44:38.000000",1.0,4.23,1.0,N,100.0,263.0,1.0,14.5,0.5,0.5,1.7,0.0,0.3,20.0,2.5

 1026  cut -d, -f3 2019-03.csv | grep "2019-03-12" | tail -20 > results.txt
(this specifically ensures we only count the 3rd column. But we lose all the other data.)
cut and -d deliminate by ",". -f look at the thrid column in the 2019-03.csv data. | grep pattern match 2019-03-12 | print the last 20 entries and redirect to txt file 


 1030  cut -d, -f3 2019-03.csv | grep "2019-03-12" | wc -l >> results.txt
(this see how many data entries are specifically "2019-03-12") 
word count -l lines and redirect the # outputed to the results.txt file >> 

 1031  cat results.txt

OUTPUT:
"2019-03-12 19:32:28.000000"
"2019-03-12 08:19:47.000000"
"2019-03-12 08:44:00.000000"
"2019-03-12 09:10:38.000000"
"2019-03-12 18:55:28.000000"
"2019-03-12 19:14:41.000000"
"2019-03-12 10:14:37.000000"
"2019-03-12 19:01:07.000000"
"2019-03-12 11:12:20.000000"
"2019-03-12 11:25:38.000000"
"2019-03-12 11:53:19.000000"
"2019-03-12 12:14:32.000000"
"2019-03-12 12:22:58.000000"
"2019-03-12 13:09:00.000000"
"2019-03-12 13:34:24.000000"
"2019-03-12 13:49:27.000000"
"2019-03-12 14:09:51.000000"
"2019-03-12 20:59:12.000000"
"2019-03-12 21:41:17.000000"
"2019-03-12 23:43:22.000000"
266324

(NOTE HOW TO DO WITH REGEX, BUT DONT LIKE BECAUSE COMPLICATED) 
grep -E '^[^,]*,[^,]*,"2019-03-12"'
(starting at the 3rd column, esentailly) 

2.) Sort the pickup location IDs in order to find the most popular pickup locations in January 2019. Identify the top 3 locations.
cut -d, -f8 2019-01.csv | sort -n | uniq -c | sort -nr | head -3
(vut the 8th column which is location ID. sort by numeric location number. uniq -c count all the location. sort by numberic and reverse. head -3 to get the top 3 loca
OUTPUT: 
 332473 237.0
 323008 236.0
 312392 161.0

3.) Sort the pickup location IDs in order to find the most popular pickup locations in February 2019. Identify the top 3 locations.
cut -d, -f8 2019-02.csv | sort -n | uniq -c | sort -nr | head -3
 294584 237.0
 286773 161.0
 280640 236.0

What if I wanted the least visited pick up locations? The problem would be that I would have the header included in the count, which we dont want. 
You can use tail and count all the ones up to starting at the second row. 

tail -n +2 2019-02.csv | cut -d, -f8 | sort -n | uniq -c | sort -nr | tail -3
      3 172.0
      2 27.0
      1 199.0
or 

tail -n +2 2019-02.csv | cut -d, -f8 | sort -n | uniq -c | sort -n | head -3 
